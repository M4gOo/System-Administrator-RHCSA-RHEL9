
#search for package
 dnf provides */mkfs.vfat

===================================== Network Manager
 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/assembly_configuring-and-managing-network-access_configuring-basic-system-settings

sudo yum -y install NetworkManager
systemctl enable NetworkManager --now

-------------------------nmtui

ip a

Just check which IP they have and add the IP is down
Make sure to change the hostname 
Make sure to activate the connection

------------------------- nmcli

ip a

nmcli con show
nmcli device status
nmcli con show "System eth0"

#edit a interface connection
nmcli con mod "System eth0" ipv4.addresses 192.168.55.150/24 ipv4.gateway 192.168.55.1 ipv4.dns 8.8.8.8 ipv4.method manual connection.autoconnect yes
nmcli con up eth0

#configure connection
sudo nmcli con add con-name "Default1" type ethernet ifname ensl60 ipv4 129.187.345.1/24 gw4 129.187.345.0
nmcli con show
nmclli con up "Default1"
nmcli con mod "Default1" connection.autoconnect yes

to change the ipaddr
nmcli con mod Default1 ipv4.addresses 192.168.12.34/24

#add DNS
nmcli con mod Default1 ipv4.dns 172.123.456.32

#add more ip to the interface
nmcli con mod Default1 +ipv4.addresses 192.168.12.88/24


-------------------------- hostname

cat /etc/hostname
hostnamectl set-hostname server1.example.com

------------------------ /etc/hosts
add the new ip address in all servers
IPserver1 server.example.com server1
IPserver2 server2.example.com server2

==================================== Recover ROOT Password from boot

hold shift OR F8 
select Rescue mode
press E
in the line linux... at the end type init=/bin/bash
Ctrl + X
mount -o remount,rw /
passwd <password_2x>
touch /.autorelabel
reboot  OR exec /usr/lib/systemd/systemd

#if keep in a loop need to troubleshooting and remove the /.autorelabel at the end


================================ Boot interface

systemctl get-default

systemctl set-default

#check list for set-default
ls -l /usr/lib/systemd/system/ 


=================================================== SSH

-----------------------root ssh
yum -y install sshd
systemctl enable sshd.service --now
vi /etc/sshd/sshd_config
  PermitRootLogin yes
systemctl restart sshd.service 

----------------------ssh root key pair
vi /etc/sshd/sshd_config
    PubkeyAuthentication yes  
ssh-keygen
cd ~/.ssh
ssh-copy-id root@server2:/root/.ssh
The plublic key it will be in ~/.ssh/authorized_keys

ssh-keygen
cd ~/.ssh
ssh-copy-id root@server1:/root/.ssh


====================================== Repository

Red Hat Enterprise Linux 9 is distributed through two main repositories:

BaseOS
AppStream
Both repositories are required for a basic RHEL installation, and are available with all RHEL subscriptions.

check repo list
dnf repolist all

 sudo vi /etc/yum.repos.d/local.repo
 
 [BaseOS]
 name=baseOS
 baseurl=http://rhgls.domain14.example.com/BaseOS  OR   http://<IPrepo>/repo/BaseOS/
 gpgcheck=0
 enabled=1
 
 [AppStream]
 name=appstream
 baseurl=http://rhgls.domain14.example.com/AppStream  OR   http://<IPrepo>/repo/AppStream/
 gpgcheck=0
 enabled=1
 
dnf/yum clean all   # update subscription management repo
dnf/yum repo list   #verify

=========================================== NFS   AUTOFS

server1 create /hosts/user1 and user2
server2 it will be the client to access those files

Server1
yum -y install firewalld autofs nfs-utils
mkdir -p /hosts/{user1,user2}
vi /etc/exports
   /hosts *(rw,no_root_squash)
systemctl enable --now nfs-server
systemctl enable firewalld --now
sudo firewall-cmd --add-service=nfs --permanent
sudo firewall-cmd --add-service=mountd --permanent
sudo firewall-cmd --add-service=rpc-bind --permanent
sudo firewall-cmd --reload
sudo firewall-cmd --list-all

vi /etc/hosts
add the new ip address in all servers
IPserver1 server1.example.com server1
IPserver2 server2.example.com server2


Server2
yum -y install autofs nfs-utils
showmount -e <IPserver1>
vi /etc/auto.master
   /hosts   /etc/auto.hosts
vi /etc/auto.hosts
   *  -rw  <IPserver1>:/hosts/&
systemctl enable autofs --now
cd /hosts/user1


------------------------ NFS
On both servers persistently mount /export/dba_files from the server 192.168.0.2 under /mnt/dba_files
vi /etc/fstab
192.168.0.2:/export/dba_files /mnt/dba_files nfs defaults 0 0 
mount -a
chown manny:dba_staff /mnt/dba_files
chmod 2770 /mnt/dba_files
chmod +t /mnt/dba_files

Ensure manny is the user owner and dba_staff is the group owner. Ensure the groupID is applied to newly created files. 

Ensure users can only delete files they have created. Ensure only members of the dba_staff group can access the directory.


================================================== UMASK
[ ~]$ umask
0002
[ ~]$ umask -S
u=rwx,g=rwx,o=rx
 
 To determine whether you are executing a command in a login or a non-login shell, use the echo $0 command.
 non-login shell. bash
 login shell.     -bash
 

To display the default bash umask for the non-login shell, use:
grep umask /etc/bashrc
You can change the default umask for a specific user by modifying the .bashrc for that user.
echo 'umask octal_value' >> /home/username/.bashrc

To display the default bash umask for the login shell, use
grep "UMASK" /etc/login.defs
The default umask for the login shell is set in the /etc/login.defs configuration file.
You can change the default bash umask for the ROOT user by modifying the /etc/login.defs file.

umask octal_value. The umask is only valid for the current shell session.


================================================== /etc/login.defs

Can edit the expiration configuration

==================================================  /etc/security/pwquality.conf
 Set password policies to require a minimum of 8 characters
uncomment
minlen = 8


=============================================  visudo

sudo command alias for MESSAGES with the command /bin/tail -f /var/log/messages

## Messages
Cmnd_Alias MESSAGES = /bin/tail -f /var/log/messages 


Enable superuser privileges
dba_managers: everything
dba_admin: SOFTWARE, SERVICES, PROCESSES
dba_intern: MESSAGES


uncomment 
Cmnd_Alias SOFTWARE = /bin/rpm, /usr/bin/up2date, /usr/bin/yum
Cmnd_Alias SERVICES = /sbin/service, /sbin/chkconfig, /usr/bin/systemctl start....
Cmnd_Alias PROCESSES = /bin/nice, /bin/kill, /usr/bin/kill, /usr/bin/killall

<user> <hosts> (<run as>) <command>
%dba_managers ALL=(ALL) ALL
%dba_admin ALL=SOFTWARE, SERVICES, PROCESSES
%dba_intern ALL=MESSAGES


================================================================ TAR / STAR
 
 create an archive requires 3 steps
    Archiving - pack those files and dir into a single file backup.tar
    Compress the archive (makes smaller size of the original) backup.tar.gz
    Copy where you would keep your backup
  
before extract always check the content and the paths  
archive also store permissions and ownership info
 
 best way to use this utility is using tar --help
 
 #
 
 tar rf archive.tar file1    add a file to tar archive
 tar cf archive.tar Pictures/  create a tar file with entirely directory content to archive
 tar cf archive.tar /home/user/Pictures/  the content it be save with the path /home/user/Pictures/
 tar xf archive.tar -C /tmp/      it will extract in the path given
 sudo tar xf archive.tar -C /tmp/      it will extract in the path given and the ownership and permission it will be preserved
 star -zc -f=/home/bob/backup.star.gz ~/files
 
 z - gzip
 bz - bzip
 c - create
 f= - file
 t - list content in .start.gz              star -t -f=backup.star.gz
 
 tar cfj /home/bob/asset_backup.tar.bz2 --absolute-names /opt/assets/

create an archive requires 3 steps
  Archiving - pack those files and dir into a single file backup.tar
  Compress the archive (makes smaller size of the original) backup.tar.gz
  Copy where you would keep your backup
  
before extract always check the content and the paths  
archive also store permissions and ownership info


=================================================== SOFT LINKS
 
 
 soft link points to a path, like a shortcut
 
 ln -s /home/user/Pictures/picture.jpg /home/user/Desktop/pictures_shortcut.jpg
 ln -s /tmp /home/bob/link_to_tmp
 
 when you list ls -l it will show the " L " at the beginning like:  lrwx------
 
 can use the command below to check the path link
 readlink pictures_shortcut.jpg
 
 if someone does change can break the link and it will be show in red when listed. to tackle that use relative paths to direct to the file 
 and not the file itself, because if someone delete it wont work the link
 
 can soft link files, directories, can be in different file systems


===================================================   HARD LINKS   - INODE 

A "hard link" is a directory entry that points to the same data on disk as a directory entry somewhere else.

stat /home/user/picture.jpg
it will show the inode. Inode remember all the pieces are store and keeps track like permissions, when modified, etc
links. usually you have one link which it will link the absolute path file to the inode

in case for example another user want to see the picture, you dont need copy and paste. This saves resource storage

ln path_to_target_file path_to_link_file
path_to_target_file - file you want to link
path_to_link_file - name of the new directory you want the pictures be copied

ln /home/user/Pictures/picture.jpg /home/new_user/Pictures/picture.jpg
ln /tmp/hlink /home/bob/hlink

if the user delete his file the new user still can have access to the pictures

limitations
  only for files, not directories
  only link on the same file system
  make sure has right permissions, the example above we might add the user and new_user to the same group ( useradd -a -G family user ,  useradd -a -G family new_user)

Verify Hard links
Use the ls -i command to view the inode number. Files that are hard-linked together share the same inode number. 


================================================================= FIND


#
find /opt/assets/ -type f -exec grep -Iq . {} \; -print        find file that contains text, when the others are empty
#
find /opt/assets -type f -perm 2664 -exec cp -p {} /home/bob/specialfiles/ \;


SUID - 4
SGID - 2
Sticky bit - 1
-exec <command> {} \;
      find will execute <command> and will substitute {} with the filename(s) found. 
      with ; a single <command> for each file is executed 
      escaped here as \; to prevent the shell from interpreting it

{} \; : executing the commands for each found result
{} + : executing the command once with all results argument like this -> ls file1.txt file2.txt file3.txt  


find /path -name file.txt
find /path -iname file.txt              -case sensitive
find -mmin        modified minute (modified means creation or editing a file) Modified means when the contens have been modified
find -mmin 5      5 min ago (if now is 11:00 it will find files in 10:55)
find -mmin -5     5 min ago (if now is 11:00 it will find files BETWEEN 10:55 until 11:00)
find -mmin +5     list files before 5 min ago (if now is 11:00 it will find files from 10:55 to the infinite 10:45, 10:30, 9:30, etc)  
find -mtime 0     search for files per days or past-24hours periods
0 past 24 hours
1 24h to 48h
  
created
find -cmin -5   created last 5 minutes
  
find / -type f -perm -u+s            Find all setuid files
find / -type f -size +3M             files larger than 3MB
find -size
c bytes
k kilobytes
M megabytes
G gigabytes
  
find -size 512k       = 512
find -size +512k      > 512
find -size -512k      < 512
                            
sudo find /usr -type f -size +5M -size -10M           Find all files between 5mb and 10mb in the /usr directory
             
find -perm 664       exactly perm
find -perm -664       find bearly perm  
find -perm -u=rw,g=rw,o=r       find bearly perm                          
find -perm /664       find files with any of these perm                          
                             
find -name "f*" -size 512k          AND operator                     
find -name "f*" -o -size 512k       OR operator  
find -not -name "f*"                NOT operator
 
Find files/directories under /var/log/ directory that the group can write to, but others cannot read or write to
sudo find /var/log/ -perm -g=w ! -perm /o=rw                          
! expr : True if ‘expr’ is false.
not to be r or w. That means, if any of these two permissions, r or w match for others, the result has to be excluded
  
  
================================================ CHMOD  - SETUID, SETGID, STICKY BIT


[S ; s (with x)] SETUID -  makes an executable run with the privileges of the owner of the file
[S ; s (with x)]SETGID -  makes an executable run with the privileges of the group of the file.
[T ; t (with x)] STICKY BIT - This permission does not affect individual files. At the directory level, it restricts file deletion. 
                              Only the owner (and root) of a file can remove the file within that directory.

4 - r
2 - w
1 - x

u - user (owner)
g - group
o - other 
a - all (u, g, and o)

sudo chmod g+rw
sudo chmod u-w
chmod go+rw 
sudo chmod g+s     ensure that for all future files within /directory the group owner will be the same as set in /directory


----------------------------------------------------------------------   CRONTAB  

cat /etc/crontab 
  can use  ',' this it will run multiple times like 15min and 45minutes -> 15,45
  can use '-', set hours to 2-4 2am,3am,4am
  can use '/', to specifies steps, every 4hours it will run. */3 * * * * ->execute every 3min
  Minute(0-59) Hour(0-23) Day_of_month(1-31) Month(1-12) Day_of_week(0-6) [Sunday=0 or 7] or sun,mon,tue,wed,thu,fri,sat
  
check the service is running in the machine
service cron status
service cron start

crontab -e 
  edit he table of your current user
  
crontab -l   - to see user logged in cronjobs

to edit as sudo just add sudo at the front
sudo crontab -l       list
sudo crontab -e       edit
30 21 * * * /usr/bin/touch test_passed

to add with different user
sudo crontab -e -u <username>

to remove cronjob
crontab -r
sudo crontab -r -u <username>

to run a sheel script in a cronjob dont add extension
makes executable
sudo chmod +rx /etc/cron.hourly/shellscript
if want run hourly (/etc/cron.hourly) just move to this dir, using sudo 

check the logs
sudo cat /var/log/cron

to send an email to user change the MAILTO=root

to deny user to do cronjob
/etc/cron.deny      #ype the name user in the file and save
to verify login with the user and try to use the command crontab -e


------------------------------------------------------   Scheduling jobs with at 
dnf install -y at
systemctl enable --now atd


just specify the time

at 15:00
at> /usr/bin/touch  file
ctrl +d to save the job

at 'December 01 2020'
at '1:30 December 01 2020'
at 'now + 30 minutes'     in 30 minutes from now

atq               to see the jobs, command to see the jobs that are scheduled to run in at utility
at -c <job_id>    to see what the jobs does

atrm <job_id>     to remove the job


sing root user, schedule below given command to run at 15:30 August 20 2024 by using at utility:
/usr/bin/touch atscheduler
Switch to the root user using sudo -i command, then execute command at '15:30 August 20 2024'
Add /usr/bin/touch atscheduler line, enter,   then save it by pressing CTRL+D

 
  
================================== Permissions

chmod 770 /path/{dir1,dir2}

you can only delete the file if you are the owner of the file, or the owner of the directory that contains the file.
when there is a stickybit!


================================= Managing users and groups
The main file used when users are created is /etc/login.defs. In this file many - but not all - default settings are defined for new user accounts.

================================== Managing Processes , NICE, RENICE

type & in the end
jobs command for check process in the background
fg <number> bring back the process to foreground
ctrl+z to pause the process 
bg to continue processes paused

----- Change process priority
start a process with different priprity
nice -n -8 dd if=/dev/zero of=/dev/null &


======================================= Check package

dnf provides */killall


========================================== SELinux

a package that is needed to do decent SELinux troubleshooting
yum -y install setroubleshoot-server    OR yum -y install setrouble*
dnf install -y policycore* setrouble*                                    #best way


---------------------------------- troubleshooting HTTP
check status http
install setrouble* and then check the messages in (/var/log/messages)

------------------Managing SELinux File Context

vi /etc/httpd/conf/httpd.conf
change DocumentRoot
<Directory>

SELinux messages are written with the audit label AVC: 
grep AVC /var/log/audit/audit.log | grep index.html

In some cases it's also useful to see if sealert has generated output. 
You'll find that in journalctl output: journalctl | grep sealert

ls -Z /var/www
ls -Z /web
semanage fcontext -a -t httpd_sys_content_t "/web(/.*)?"         # man semanage fcontext (good to check the syntax)
restorecon -Rv /web


-------------------- Managing SELinux Port

system not able to connect to httpd service port 82.     # need to change the port, check firewall as well
semanage port -l | grep http
semanage port -a -t http_port_t -p tcp 82
semanage port -l | grep http_port_t    #to check if it worked adding port 82 the output should give: http_port_t   tcp   82, 80, 81, 443, 488, 8008, 8009, 8443, 9000
firewall-cmd --permanent --add-port=82/tcp
6 - firewall-cmd reload
7 - firewall-cmd --list-all    #verify the rules
check the conf file for http ### vi /etc/httpd/conf/httpd.conf
#Supplement Configuration and check the configurations
also go to Listen and change the port number
sudo systemctl daemon-reload 
systemctl restart httpd


============================== Containers

sudo yum -y install container-tools


------------------ Auto-starting Rootless Containers
1 - need a non-root user acc
  useradd <username>
  passwd <username>

2- enable linger
What is enable linger?
If enabled for a specific user, a user manager is spawned for the user at boot and kept around after logouts. 
This allows users who are not logged in to run long-running services.

  loginctl enable-linger <username>
  loginctl show-user linda        # verify Linger=yes

3 - Need to ssh to the user. It needs to be a real login, su doesn't work.
  ssh <username>@localhost
  
4 - Create a container
  podman run -d --name mynginx -p 8081:80 docker.io/library/nginx

5 - Generate a systemd unit file to autostart the container
   mkdir -p ~/.config/systemd/user
   cd ~/.config/systemd/user
   podman generate systemd --name mynginx --files
   cat container-mynginx.service          #check the content
   systemctl --user daemon-reload
   
6 - automatically start the user container on boot
  podman stop mynginx
  systemctl --user enable --now container-mynginx.service
  systemctl --user status container-mynginx.service       # verify
  podman ps                                                     #verify the container


 =================================== NFS ======== AUTOMOUNT


------------------ NFS server
dnf install -y nfs-utils

In NFS you'll need to share something. Let's create a dummy user homedirectory structure which can be shared next: 
mkdir -p /users/nfs/{lisa,linda,anna}

 tell NFS to share the directory containing these user home directories. To do so, it needs a file /etc/exports 
 that contains the name of the directory to share, including some access permissions: 
 echo "/users *(rw,no_root_squash)" > /etc/exports

Enable and verify the NFS server
systemctl enable --now nfs-server

The showmount command provides an easy way to test NFS server access. 
In this case it's super-easy, as the NFS server isn't even running remotely. 
That's why you don't have to configure any firewall either. Use the following command to verify the NFS shares are available: 

showmount -e localhost
Export list for localhost:
/users *

You'll see that the directory /users is exported, which means that it's time to take care of automount setup.

To use automount, you need to install the autofs service.
As autofs doesn't really have any configuration yet, it doesn't make much sense to start it at this point already
dnf install -y autofs


Create the automount configuration
The automount configuration is stored in two files. 
The /etc/auto.master file is used to identify the directory that automount will manage, as well as the file that is used for further configuration.

to add a line to the auto.master file: 
echo "/home/nfs  /etc/auto.nfs" >> /etc/auto.master   
   
   
You need wildcards to refer to any directory, and to refer to the matching part on the NFS server, you need an ampersand. 
So to create the automount configuration, use 
echo "*   -rw   localhost:/users/nfs/&" > /etc/auto.nfs

This completes the configuration, so it's time to start and enable the autofs service: 
systemctl enable --now autofs

Verify the mounts
ls -al /home/nfs

In the previous step you've seen that the /home/nfs directory didn't contain any subdirectories. That is expected, because autofs will only become active when one of the subdirectories is actually accessed. 
For a home directory, that would happen automatically when the user is logging in. Use the following to simulate this: 
cd /home/nfs/linda

Type pwd to verify that you are indeed in the directory /home/nfs/linda, which has now been automounted for you.

To understand a bit more about all that is happening in the background, use 
mount | tail -5 
where you'll see the mounts that have been created by autofs.

