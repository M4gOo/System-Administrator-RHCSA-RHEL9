  
  ======================================             Essential Tools                    ===================================================================


save all command output (both errors/warnings and normal output
sudo ./script.sh > /home/bob/output.txt 2>&1 
#
id  uid,gid,...
#
who  users log in the current system
#
last  show the logged in users
#
su -  switch users, this requires the password for the user you are switching to
#
sudo  better option for su, prompt to type the user is logged in. Default conf (/etc/sudoers), this can be update using visudo
#
under /etc/sudoers  for users to run specific commands: user localhost=/usr/bin/shutdown -r now
                    can set up shell /usr/bin/nologin -> this means noone can login into the system using root user and password directly
                              
   the number 3 in brackets is user:group that first field can run the command

bob = ALL(ALL:ALL) ALL
bob - user
%bob - group
ALL (column 2) - localhost
ALL:ALL - user:group
ALL (column 4) - command, could be /usr/bin/shutdown -r now; /bin/ls; etc


absolute path always start with the /
  relative example you are /home/user and want to move to /var/log -> cd /var/log
  

when copy it is a good practice to terminate with / whne it is directory
#
cp file.txt dir/
cp file.txt dir ->this dir could be a file
cp -r (recursive - it will copy the directory (including all its contents)) cp -r /tmp/Invoice /home/user   It will have /home/user/Invoice/files
cp -r Copy/ Paste/  with the paste dir already exist it will be under Paste/ this Paste/Copy/files and dir
                    with the paste dir doesnt exist it will be under Paste/ this Paste/files and dir
when use move command mv, doesnt need to use the flag -r
cp -a  (keep the attributes) - to learn more read this - https://medium.com/for-linux-users/linux-file-attributes-made-easy-8d100c0a5813
(to deal with the attributes of the files install the package sudo yum install e2fsprogs)
lsattr myfile.txt 
--------------e----- myfile.txt


#
rm -r to delete directories
  
#  
 mkdir and subdirectories ( -p flag)
 mkdir -p /tmp/1/2/3/4/5/6/7/8/9

Move all content of
#
mv /home/bob/dir/* /home/bob/new-dir/

list full time
#
ls --full-time


===================================================== Hostnamectl & /etc/hostname

If you wish to permanently change the hostname without rebooting your computer, use the hostnamectl command

#
hostnamectl set-hostname name
#
hostnamectl set-hostname -H [username]@hostname
#
hostanamectl status
#
sudo vi /etc/hostname

then 
sudo systemctl restart NetworkManager
reboot

can use sudo nmtui     #if doesnt have the package install using sudo yum -y install NetworkManager-tui*


==================================================== APROPOS 

If the apropos command does not work because your manual pages are not indexed
Getting this message "nothing appropriate."

#
mandb
#
apropos "nfs mount"

check manuals programs packages installed on the system /usr/share/doc


=================================================== SOFT LINKS
 
 
 soft link points to a path, like a shortcut
 
 ln -s /home/user/Pictures/picture.jpg /home/user/Desktop/pictures_shortcut.jpg
 ln -s /tmp /home/bob/link_to_tmp
 
 when you list ls -l it will show the " L " at the beginning like:  lrwx------
 
 can use the command below to check the path link
 readlink pictures_shortcut.jpg
 
 if someone does change can break the link and it will be show in red when listed. to tackle that use relative paths to direct to the file 
 and not the file itself, because if someone delete it wont work the link
 
 can soft link files, directories, can be in different file systems


===================================================   HARD LINKS   - INODE 

A "hard link" is a directory entry that points to the same data on disk as a directory entry somewhere else.

stat /home/user/picture.jpg
it will show the inode. Inode remember all the pieces are store and keeps track like permissions, when modified, etc
links. usually you have one link which it will link the absolute path file to the inode

in case for example another user want to see the picture, you dont need copy and paste. This saves resource storage

ln path_to_target_file path_to_link_file
path_to_target_file - file you want to link
path_to_link_file - name of the new directory you want the pictures be copied

ln /home/user/Pictures/picture.jpg /home/new_user/Pictures/picture.jpg
ln /tmp/hlink /home/bob/hlink

if the user delete his file the new user still can have access to the pictures

limitations
  only for files, not directories
  only link on the same file system
  make sure has right permissions, the example above we might add the user and new_user to the same group ( useradd -a -G family user ,  useradd -a -G family new_user)

Verify Hard links
Use the ls -i command to view the inode number. Files that are hard-linked together share the same inode number. 


================================================================= FIND


#
find /opt/assets/ -type f -exec grep -Iq . {} \; -print        find file that contains text, when the others are empty
#
find /opt/assets -type f -perm 2664 -exec cp -p {} /home/bob/specialfiles/ \;


SUID - 4
SGID - 2
Sticky bit - 1
-exec <command> {} \;
      find will execute <command> and will substitute {} with the filename(s) found. 
      with ; a single <command> for each file is executed 
      escaped here as \; to prevent the shell from interpreting it

{} \; : executing the commands for each found result
{} + : executing the command once with all results argument like this -> ls file1.txt file2.txt file3.txt  


find /path -name file.txt
find /path -iname file.txt              -case sensitive
find -mmin        modified minute (modified means creation or editing a file) Modified means when the contens have been modified
find -mmin 5      5 min ago (if now is 11:00 it will find files in 10:55)
find -mmin -5     5 min ago (if now is 11:00 it will find files BETWEEN 10:55 until 11:00)
find -mmin +5     list files before 5 min ago (if now is 11:00 it will find files from 10:55 to the infinite 10:45, 10:30, 9:30, etc)
  
find -mtime 0     search for files per days or past-24hours periods
0 past 24 hours
1 24h to 48h
  
created
find -cmin -5   created last 5 minutes
  
find -size
c bytes
k kilobytes
M megabytes
G gigabytes
  
find -size 512k       = 512
find -size +512k      > 512
find -size -512k      < 512
                            
sudo find /usr -type f -size +5M -size -10M           Find all files between 5mb and 10mb in the /usr directory
             
find -perm 664       exactly perm
find -perm -664       find bearly perm  
find -perm -u=rw,g=rw,o=r       find bearly perm                          
find -perm /664       find files with any of these perm                          
                             
find -name "f*" -size 512k          AND operator                     
find -name "f*" -o -size 512k       OR operator  
find -not -name "f*"                NOT operator
 
Find files/directories under /var/log/ directory that the group can write to, but others cannot read or write to
sudo find /var/log/ -perm -g=w ! -perm /o=rw                          
! expr : True if ‘expr’ is false.
not to be r or w. That means, if any of these two permissions, r or w match for others, the result has to be excluded
  
  
================================================ CHMOD  - SETUID, SETGID, STICKY BIT


[S ; s (with x)] SETUID -  makes an executable run with the privileges of the owner of the file
[S ; s (with x)]SETGID -  makes an executable run with the privileges of the group of the file.
[T ; t (with x)] STICKY BIT - This permission does not affect individual files. At the directory level, it restricts file deletion. 
                              Only the owner (and root) of a file can remove the file within that directory.

4 - r
2 - w
1 - x

u - user (owner)
g - group
o - other 
a - all (u, g, and o)

sudo chmod g+rw
sudo chmod u-w
chmod go+rw 
sudo chmod g+s     ensure that for all future files within /directory the group owner will be the same as set in /directory

=================================================================== HEAD, TAIL, TAC


  tac file.txt   -> will see bottom to top  inside the file which is small
  
  cat file.txt    -> top to bottom inside the file which is small
  
  tail file.txt   ->  will see bottom to top  inside the file which is large, default is 10 lines
  
  tail -n 20 file.txt ->  will see bottom to top  inside the file which is large, shows 20 lines
  
  head file.txt   ->  will see top to bottom  inside the file which is large, default is 10 lines
  
  head -n 20 file.txt ->  will see top to bottom   inside the file which is large, shows 20 lines
  
  head -5 file.txt  ->  will see top to bottom   inside the file which is large, shows 5 lines
  
  
 ===================================================================  SED 
  
  sed 's/old_string/new_string/g' file.txt
  s -> substitute
  g -> global replace
  
  sed -i 's/old_string/new_string/g' file.txt
  -i -> will edit the file, it will swap the strings
  
  sed -i 's/disabled/enabled/gi'
  gi - ignore case sensitive. For example, any string like disabled, DISABLED, Disabled
  
  
  Change all values enabled to disabled only from line number 500 to 2000.
  
  sed -i '500,2000s/enabled/disabled/g' file
  
  Replace all occurrence of string #%$2jh//238720//31223 with $2//23872031223 i
  
  sed -i 's~#%$2jh//238720//31223~$2//23872031223~g' file
  
  
  
=================================================================== DIFF

analyze files, see the differences between them 
for the flags is good to look at diff --help

diff file1 file2
diff -c file1 file2 
diff -y file1 file2  (side by side)
sdiff -y file1 file2  (side by side)  



=================================================================== CUT

 cut -d ';' -f 2 testfile
 cut -d ' ' -f 1 file.txt    first column that appears on each line
 d - delimiter
 ' ' -> words are separated by space, ',' words separated by comma
 f -> fields we want extract
 

=================================================================== GREP 


egrep -w '[A-Z][a-z]{2}' /etc/nsswitch.conf           starts with a capital letter and are then followed by exactly two lowercase letters  
grep -r [A-Z,a-z] /opt/assets/                        find file that contains text, when the others are empty. And also print the content
egrep '[0-9]{5}' textfile                             file there's a number that has 5 digits
grep -c '^2' textfile                                 how many numbers begin with a number 2
grep -ic '^SECTION' testfile                          how many lines begin with string Section
grep -w man testfile                                  match the only word
grep -o 'string' /path                                output it will show only the word
grep '^start' file                                    begin with start
grep man file                                         any word with man. Like man, manpath, manual
grep 'man$' file                                      $ - end of the line. Any line in which man is the last character on the line.
grep -r 'c.t' /etc                                    execute, cat, cut
grep -wr 'c.t' /etc/                                  cat, cut, cpt
grep '\.' file                                        to search for DOT in a file
grep '/.*/' /etc/                                     to search anything with /bla/, / /, /path/hello
egrep 'disabled?' file                                will search for disabled, disable
egrep 'disabled|enabled' file                         match one thing or the other

to avoid to use \ and get confuse with . and so on. It is good practice to use grep -E or egrep

egrep -r '0{3,}' /path/                              to find at least 3 zeros 
egrep -r '0{3}' /path/                               exactly 3 zeros
egrep -r '0{3,5}' /path/                             range of zeros
 


-c : count
-i : ignore string case
-w : exactly word
-r : recursive search


================================================================ TAR / STAR
 
 create an archive requires 3 steps
    Archiving - pack those files and dir into a single file backup.tar
    Compress the archive (makes smaller size of the original) backup.tar.gz
    Copy where you would keep your backup
  
before extract always check the content and the paths  
archive also store permissions and ownership info
 
 best way to use this utility is using tar --help
 
 #
 
 tar rf archive.tar file1    add a file to tar archive
 tar cf archive.tar Pictures/  create a tar file with entirely directory content to archive
 tar cf archive.tar /home/user/Pictures/  the content it be save with the path /home/user/Pictures/
 tar xf archive.tar -C /tmp/      it will extract in the path given
 sudo tar xf archive.tar -C /tmp/      it will extract in the path given and the ownership and permission it will be preserved
 star -zc -f=/home/bob/backup.star.gz ~/files
 
 z - gzip
 bz - bzip
 c - create
 f= - file
 t - list content in .start.gz              star -t -f=backup.star.gz
 
 tar cfj /home/bob/asset_backup.tar.bz2 --absolute-names /opt/assets/

create an archive requires 3 steps
  Archiving - pack those files and dir into a single file backup.tar
  Compress the archive (makes smaller size of the original) backup.tar.gz
  Copy where you would keep your backup
  
before extract always check the content and the paths  
archive also store permissions and ownership info


===================================              Operate Running Systems                         ======================================

===================================================  Boot, reboot, and shutdown a system safely


systemctl - system control

sudo systemctl restart <service>

sudo systemctl reboot
sudo systemctl poweroff

sudo systemctl reboot --force
sudo systemctl poweroff --force

to "press" reset button
sudo systemctl reboot --force --force

"unplug" the system
sudo systemctl poweroff --force --force

to schedule a time to reboot or/and shutdown
sudo shutdown 02:00   (2am)
sudo shutdown +15     in 15min shutdown
sudo shutdown -r 02:00    reboot -r
sudo shutdown -r +15      reboot in 15min
sudo shutdown -r +1 'Shceduled restart to do an offline-backup of our database'  -  single quotes, message to tell the user a message before reboot/shutdown
sudo shutdown -c    to cancel shutdown


===================================================  Boot or change system into different operating modes


system's current default boot target can be basic.target, graphical.target , etc

to check our default boot
systemcl get-default
graphical.target

#
systemctl get-default
systemctl set-default
ls -l /usr/lib/systemd/system/

sudo systemctl set-default multi-user.target  
sudo systemctl isolate graphical.target  (temporary gives a graphical prompt, after reboot back to the default you set to boot)
sudo systemctl isolate emergency.target   (for troubleshooting, read permissions, few system are loaded). You must have root password
sudo systemctl isolate rescue.target      (root permission, there will be more programs than emergency). You must have root password

systemd targets
Targets in systemd act as synchronization points during the start of your system.
The purpose of target units is to group together various systemd units through a chain of dependencies.
The graphical.target unit for starting a graphical session, starts system services such as the GNOME Display Manager 
(gdm.service) or Accounts Service (accounts-daemon.service), 
and also activates the multi-user.target unit.

basic
unit target covering basic boot-up

rescue
unit target that pulls in the base system and spawns a rescue shell

multi-user
unit target for setting up a multi-user system

graphical
unit target for setting up a graphical login screen

emergency
unit target that starts an emergency shell on the main console. provides the most minimal environment possible and allows you to repair your system even 
in situations when the system is unable to enter rescue mode. In emergency mode, the system mounts the root file system only for reading, 
does not attempt to mount any other local file systems, does not activate network interfaces, and only starts a few essential services.

sysinit
unit target that pulls in the services required for system initialization


===========================================================  Interrupt the boot process in order to gain access to a system 

When the PC is start, press down when you see the grub boot screen and chose one of the kernel and press E
at the bottom type rd.break. When boot it will be in the emergency mode
this command can help when you lost the root password on RHEL8
mount -o remount,rw /sysroot
cd /sysroot
chroot /sysroot
passwd root
touch /.autorelabel -hidden file in the root dir
reboot
exit

on RHEL9
When the PC is start, press down when you see the grub boot screen and chose one of the kernel and press E
at the second line after r\o and before crashkernel
change r\o to r\w
ctrl + e - to go to end of line
init=/bin/bash
ctrl + x
passwd (after reboot, in the terminal as root)
touch /.autorelabel -hidden file in the root dir. this fix the SELinux config
exec /sbin/init


===================================================================   Install, configure and troubleshoot bootloaders


On a system booting through legacy BIOS mode, what file would you edit before generating a new grub configuration file
/etc/default/grub

what command would you use to generate the new grub configuration file
grub2-mkconfig -o /boot/grub2/grub.cfg

one of the programs that loads up when turn on the computer it is a bootloader, this is to start the linux kernel
popular bootloader on linux is the GRUB

problem with the bootloader so the OS wont boot at all. We can use an USB sticky and boot from there using troubleshooting
then select - Rescue a CentOS Stream system 
choose option 1
chroot /mnt/sysroot
grub2-mkconfig -o /boot/grub2/grub.cfg   - generate a GRUB conf file when you have BIOS
grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg   - generate a GRUB conf file when you have EFI

Install grub to /dev/vda
#
lsblk - need to set the grub at the beginning of the disk, first check the block device (check for sd or vd), look for /boot, /
grub2-install /dev/sda
dnf resinstall grub2-efi grub2-efi-modules shim (this is for EFI only)
exit


change GRUB conf
sudo vim /etc/default/grub
sudo grub2-mkconfig -o /boot/grub2/grub.cfg
grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg - this is only for EFI
sudo systemctl reboot


========================================================================== Diagnose and manage processes

man ps   -then type /EXAMPLES

ps a is different than ps -a

ps will show programs launched in our current terminal window or session

ps aux -display all process in the machine. 
        ax show all process
        u list processes in a user oriented format (can see useful column like CPU and memory)
        
top
ps <PID>
ps u <PID>    cpu and memory
ps -U <username>
ps u -U <username>
pgrep -a <process>


------------------------------------------         niceness value

Niceness value is a number attached to processes in *nix systems   
is used to decide how much CPU time is allocated to it.
used to change the priority of a process, which, in effect, determines the urgency with which it is executed in the system. 
The nice command configures the priority of a Linux process before it is started. 
The renice command sets the priority of an already running process.

 -20 the highest priority
 +19 lowest
 
 By default, any Linux process created by a user has a nice value of 0
 
 check the nice (NI)
 #
 ps -l
 ps -le | grep <service>
 top
 ps lax
 
 #
 sudo renice -n <-20 to 19>  -p <PID>
 nice -nice_value command-arguments
 sudo renice -n 5 -u <username>       modify the priority of all processes owned by a group
 sudo renice -n 5 -g <groupname>      modify the priority of all processes owned by a user

nice -n 11 <process>    

regular user can only assign nice number between 0 to 19

ps l    will show the nice value in the column (NI)

to change the nice number when the process is up
sudo renice <nice_value> <PID>

-----------------------------------------------------------  to give signals to the programs - SIGHUP SIGKILL

#
sudo kill -SIGHUP <pid>

The SIGHUP signal is used by some utilities as a way to notify the process to do something, such as re-read its configuration file. 
The SIGHUP signal is also sent to a process if the remote connection is lost or hangs up. 
The SIGKILL signal is used to abort a process, and the SIGSTOP signal is used to pause a process.

list of signals 
kill -L


------------------------------------------------------  background and foreground process

ctrl + Z -> background process. the process will be frozen
fg        -> bring back to foreground


to run in back ground use the &
sleep 300&

check commands in the background  
jobs  
when you use the & and wants bring back use
jobs command to see the programs are running and also the number then
fg <select_the_number>

if the job is stopped with ctrl+z  use the jobs command to check the number and then use
bg <select_the_number>


------------------------------------------------------ LSOF

what files or dir resources using right now
for example to see which files and dir bash process is currently using
lsof
ls - list
of- open files

sudo lsof -p <PID>

lsof command is mainly used to retrieve information about files that are opened by various processes. 
Open files in a system can be disk files, network sockets, named pipes and devices.
The lsof command stands for LiSt Open Files and shows open files and which process uses them

#
lsof -p <PID>
lsof /proc
lsof -u admin
lsof -i TCP:22

sudo lsof | grep sshd |  grep -i reg | sed 's/.* //g' > /home/bob/sshdfiles.txt


============================================================================== Locate and analyze system log files 


log daemon rsyslog is the popular in Linux that stores all logs in /var/log

ls /var/log/

grep -r 'ssh' /var/log/

system logs
/var/log/messages
/var/log/

tail -F /var/log/secure   (you can watch the log waiting for inputs; liveview)

journalctl              ( > you can use to navigate)
journalctl /bin/sudo
journalctl -u sshd.service
journalctl -e                 (go to end to the journalctl)
journalctl -F                 (liveview)
journalctl -p err             (use journalctl -p to list those using 2 TAB -> (err, alert, crit, debug, emerge, info, notice, warning, ...))
journalctl -S 02:00                     -S for specify time
journalctl -S 01:00 -U 02:00            logs started in 01:00 to 02:00
journalctl -S  '2021-11-16 12:04:55'
sudo journalctl -p info -g '^c'               Analyse the info priority logs through journalctl that begin with letter c
journalctl logs are reset after reboot/power off, to save create /var/log/journal/


to see who is logged in the system
last     
lastlog  (ssh will see an IP addr)


=================================================================         Manage tuning profiles 

tuned is a service that monitors your system and optimizes the performance under certain workloads
like High throughput systems, low latency and power saving

when installed it will automatically selects what it believes is the best profile for youyr system
if the High throughput is selected in a VM the virtual guest profile would get selected

Sysadmins can use the static profiles to define specific performance parameters or allow the system to switch profiles dynamically 
depending on the existing workload.
A profile is a set of rules that defines certain system parameters such as disk settings, kernel parameters, network optimization settings, 
and many other aspects of the system.


sudo yum install tuned
sudo systemctl enable --now tuned
tuned-adm --help
tuned-adm active                                                    show the active profile
sudo tuned-adm profile virtual-guest powersave                      Apply the powersave profile in addition to the current active profile. 
tuned-adm verify
tuned-adm list
tuned-adm profile balanced
tuned-adm profile_info
tuned-adm recommend
tuned-adm auto_profile
tuned-adm profile_mode
/usr/lib/tuned                tuned profiles are located
/etc/tuned                    main configuration custom profiles
/etc/tuned/tuned-main.conf     find out the required status



=========================                Configure Local Storage                ======================================================

Divide a storage device is called partitioning

check partitions in linux
#
lsblk 
to be a partition in the output must show part ion the type column
virtual machines storages devices typically begin with V
s SATA
nvme  NVMe


----------------------------------------- fdisk
fdisk pre installed partitioning utility. This command shows a list of partitions on this block
storage devices is divided into sectors
check the partition  and with the number in start column multiple with the sector size it will have the Sectors column which will be the size, this
means that the partition has the size of free space before that sectors 0 to 2047 (2047 for example is the number shown in the Start column)
it is good to leave at least 1G free for bootloader in case needs to be install in that area. This method is MBR

#
sudo fdisk --list /dev/sda

sudo fdisk -l  /dev/vde
Disk /dev/vde: 1 GiB, 1073741824 bytes, 2097152 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0xc67b0eb1

Device     Boot Start     End Sectors  Size Id Type
/dev/vde1        2048 2097151 2095104 1023M  b W95 FAT32


#
You need to run the command for every partition, the defaults it will change for each partition (the utility will give the defaul option)
Create 3 primary partitions on /dev/vdb
first 10MB
second 21MB 
third 15MB

sudo fdisk /dev/vdb

Command (m for help): n
Select (default p):  <just-leave-it-default-and-press-enter>
Partition number (1-4, default 1): <just-leave-it-default-and-press-enter>
First sector (2048-2097151, default 2048):  <just-leave-it-default-and-press-enter>
Last sector, +sectors or +size{K,M,G,T,P} (2048-2097151, default 2097151): +10M
Command (m for help): w

#
partprobe /dev/vdb

to check use 
lsblk
vdb    253:16   0   1G  0 disk 
├─vdb1 253:17   0  10M  0 part 
├─vdb2 253:18   0  21M  0 part 
└─vdb3 253:19   0  15M  0 part 


-------------------------------------- cfdisk
#
sudo cfdisk /dev/sdb

GPT less likely to be corrupted and many more primary partitions and use much larger partitions
gpt = gpt
dos = mbr

can select swap space


====================================================         Configure and manage swap space

swap area wher linux can temporarily move some data from the computer RAM
when you open a program and it is just there doing nothin and you want to open a browser, even doesnt have enough memory, linux
will move the memory used in the program, which you havent done much, and move the memory to swap partition.

Swap is a space on a disk that is used when the amount of physical RAM memory is full. When a Linux system runs out of RAM, 
inactive pages are moved from the RAM to the swap space.

Create a file that will be used for swap
If falllocate is not installed or if you get an error message 
#
sudo fallocate -l 1G /swapfile

to check if the system uses any kindof swap areas
swapon --show

to make a partition be a swap area
sudo mkswap /dev/vdb3   (check first with the command lsblk) - this command format a partition as swap space
sudo swapon --verbose /dev/vdb3

in /etc/fstab 
/dev/vdb2 swap swap defaults 0 0

But if you reboot the system the partition wont be used as swap
sudo swapoff /dev/vdb3   stop using the partition as swap

create a  file with empty zeros
sudo dd if=/dev/zero of=/swap bs=1M count=128 status=progress
dd will copy the if file to of, count means to write 1 megabyte block 128 times. it will be 128Megabytes

make sure so set proper permissions
sudo chmod 600 /swap

then
sudo mkswap /swap
sudo swapon --verbose /swap


Increase the existing swap (i.e /swapfile) size by 1GB
sudo dd if=/dev/zero of=/swapfile bs=1M count=1024 oflag=append conv=notrunc
sudo swapoff /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile


remove Swap File 
#
sudo swapoff -v /swapfile
Remove the swap file entry in /etc/fstab
sudo rm /swapfile

----------------------------- swap partition with fdisk

fdisk /dev/vdb
n
default
default
+size

change the type for swap partition
t
default
L            # usually is 82 linux swap
82
w
partprobe /dev/vdb     #partprobe is a program that informs the operating system kernel of partition table changes.

mkswap /dev/vdb1

/etc/fstab

/dev/vdb1 swap swap defaults 0 0 

swapon -a

free -m    #to verify the total swap size
===========================================================      Manage and configure LVM storage 

lvm = logical volume manager
free spaces in multiple portions of disk or if we have multiple discs that we would like to combine together

man lvm
check some commands can type
vg in the terminal
pv
it will show a list of commands
PE - physical extend


sudo dnf install lvm2
pv -  physical volumes
 sudo lvmdiskscan     OR           sudo pvs                         when pvcreate you can check the disks are LVM
 sudo pvcreate /dev/sdc /dev/sdd
 sudo vgcreate <type_any_name_for_groupname> /dev/sdc /dev/sdd
 sudo vgextend  <type_groupname> /dev/sde                           to extend the volume group
 sudo vgs                                                           list volumes groups
 sudo vgreduce  <type_groupname>   /dev/sde                         to remove a physical volume from the volum group
 sudo pvremove /dev/sde                                             to remove entirely from lvm
 sudo lvcreate --size 2G --name partition1  <type_groupname>        need to add a partition, need to add a logical volume 
 sudo lvresize --extents 100%VG  my_volume/partition1               to grow the logical volume after partition the disk
 sudo lvresize --size 2G   my_volume/partition1                     to shrink
 sudo lvdisplay                                                     check the lv and pv
 sudo lvremove volume1/smalldata                                    to remove the partition
 sudo mkfs.xfs   /dev/<type_groupname>/partition1                   to store files and dir on a logical volume we need a filesystem
 
 sudo lvresize --resizefs --size 3G <type_groupname>/partition1     to resize a logical volume with the filesystem
 sudo lvresize -L 1G  volume1/smalldata                             example of resize
 
 sudo mkfs.xfs /dev/volume1/smalldata                               create a file system for a LV
 sudo fsck /dev/volume1/smalldata     OR  lsblk -f                  check the file system for the partition
 
 
 /etc/fstab
 /dev/volumegroupname/logicalvolume /mountpoint defaults 0 0
 
 lvextend -r -L +2G /dev/volumegroupname/logicalvolume    # to extend, but make sure the volume group has this size to extend
 vgextend volumegroupname /dev/vdc
 
 L - you know the size
 l - %, extends number
 
 extend PE
 vgcreate -s 8M volumegroupname /dev/vdc
 
  lvcreate -l 10 -n logicalvolumename /dev/volumegroupname
  
 =================================================================       Create and configure encrypted storage
 
 
 plane mode - we need to open the device 
 sudo cryptsetup open --type plain /dev/vde mysecuredisk
 open is to open the device for reading encrypted data from it and writing encrypted data to it
 mysecuredisk is the name of the disk you want
 --verify-passphrase is to type twice the password,because the plane mode doesnt check if the password is not correct
 
 it will be saved in /dev/mapper/mysecuredisk
 act like a disk, which you can mount, create file system 
 sudo mkfs.xfs /dev/mapper/mysecuredisk
 sudo mount /dev/mapper/mysecuredisk /mnt            TO unmount -> sudo umount /mnt
 it is important to close otherwise can be readable in /dev/mapper
 sudo cryptsetup close mysecuredisk
 
 
  
 LUKS - need format the storage and open
 another way to encypt and easier. Format the disk or partition we intend to use with linux encryption
 sudo cryptsetup luksFormat /dev/vde        /dev/vde is formatted to be used with LUKS encryption. /dev/vde should be mapped to an unencrypted device called secretdisk
 sudo cryptsetup open /dev/vde mysecuredisk  
 sudo cryptsetup luksChangeKey /dev/vde      change the password the encryption key
 once formatted can open using
 we dont need specify the type of encryption when we format a device with Luks that writes a very small block of data to the storage
 called header
 sudo mkfs.xfs /dev/mapper/mysecuredisk
 sudo cryptsetup close mysecuredisk
 sudo cryptsetup luksFormat /dev/vde2        to encrypt part of the disk, only the partition
 sudo cryptsetup open /dev/vde2 mysecuredisk
 
 
 ===========================================================================  Create and manage RAID devices 
 
 raid 0 - stripped, if we lose one disk all data will be lost
 raid 1 - redundant, mirror array, clone all data in all storages
 raid 5 - min 3 disk, has parity on each disk (used to rebuilt in lost of data), can lose 1 disc
 radi 6 - 4 discs, can lose 2 discs and still recovers data
 raid 10  - combination level 0 and 1
 
 sudo yum -y install mdadm
 sudo mdadm --create /dev/md0 --level=0 --raid-devices=3 /dev/vdc /dev/vdd /dev/vde
 sudo mkfs.ext4 /dev/md0
 sudo mdadm --stop /dev/md0    to stop or deactivate an array
 sudo mdadm --zero-superblock /dev/vdc /dev/vdd /dev/vde   to avoid the linux when bootup looking for arrays, if dont use this command linux will 
 built the array 
 sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/vdc /dev/vdd --spare-devices=1 /dev/vde      add spare disk in an array
 
 add/remove more disks on the array /dev/md0
    #
    sudo mdadm --manage /dev/md0 --add /dev/vde          
    sudo mdadm --manage /dev/md0 --remove /dev/vde 
 
 #
  cat /proc/mdstat             look the status of array
 
 in /etc/fstab
 /dev/md0 /raid xfs defaults 0 0
 
 
================================================================    Create, manage and diagnose advanced file system permissions 
 
 ACLs (Access Control Lists) defines specific permissions for two or more users/groups
 
 sudo setfacl --modify user:<username>:rw file.txt
 sudo setfacl -m group:Mac:--- /var/fstab             group Mac wont have any permissions
 
 when you use the command ls -l will see a + mark at the end
 to check tha acl in the file
 getfacl file.txt                                             the output shows the mask, which means the maximum permission we can get in that file
 
 sudo setfacl --modify mask:r file.txt                                  to set/change a mask
 sudo setfacl --remove user/group:<username/groupname> file.txt         to remove acl group/user
 sudo setfacl --recursive -m user:<username>:rw dir/                    to set ucl dir and subdir/files as well
 sudo setfacl --recursive --remove user:<username> dir/                 to remove ucl dir and subdir/files as well


set permissions for user which all new creating files will be -r-------- and dir dr-x------ as default permission
vi .bash_profile
#after fi type
umask 277

========================================================== chattr, lsattr

cannot delete the file even the owner or root
to only append to a file, this way you can not overwrite like
echo hi > file1 it wont work
run the command
sudo chattr +a file1
echo hi> file1   -> the output shows operation not permitted
echo hi >> file1   -> it will work after run the program chattr
sudo chattr -a file1     to remove the append
sudo chattr +i file1   immutable cannot be change, even the root cannot do it. To remove instead +i type -i
lsattr file1    to show the permissions set


================================================================  Setup user and group disk quotas for filesystems 

quotas is a simple way to limit how much storage space each user or group can use

sudo dnf install quota
sudo vim /etc/fstab
      /dev/vdb1 /mybackups xfs ro,noexec 0 2
      /dev/vdb1 /mybackups xfs defaults,usrquota,grpquota 0 2   ->add defaults,usrquota,grpquota
 then save the file and reboot
 sudo systemctl reboot
 sudo quotacheck --create-files --user --group /dev/vdb2       it will create to files in a filesystem aquota.group and aquota.user
 sudo quotaon /mnt    this is when you mount in /mnt
 
 create a file with a specific size
 fallocate --length 100M /path/dir/100Mfile
 
 to edit quotas to a user
 sudo edquota --user <username>
 sudo quota --user <username>    if the user use more than capacity, it will have a grace period wwith that the user wont be able to write any data
 sudo quota --edit-period        to edit the grace period, soft limit
 sudo edquta --group <group_name>


Edit disk quotas for the user called john. Set a soft limit of 100 megabytes and hard limit of 500 megabytes on /mnt partition.
sudo xfs_quota -x -c 'limit bsoft=100m bhard=500m john' /mnt/



=========================                Create and Configure File Systems                ======================================================

----------------------------------------------------  mkfs
centOS use xfs file system, but can use ext4

sudo mkfs.xfs /dev/sdb1    
sudo mkfs.ext4 /dev/sdb1

sudo mkfs.xfs   - it will show many flags we can use
xfs             - double TAB to check more utilities

sudo mkfs.xfs -L "DataDisk" /dev/vdb          label DataDisk
sudo tune2fs -l /dev/sdb2                     this is to change in the ext4 filesystem
sudo mkfs.ext4 -N 2048 /dev/vdc               ext4 filesystem with a number of 2048 inodes on /dev/vdc
man mkfs.ext4
man mkfs.xfs

/etc/fstab
/swap_file none swap defaults 0 0             add swap after boot
/swap_file swap swap defaults 0 0


===================================================================   Create, mount, unmount, and use vfat file systems

------------------------------------------------------- vfat   

vfat virtual file allocation table
is used primarily for compability reasons, every OS can read files from vfat file systems
is used to share storage between windows and linux

to change the partition type use
sudo fdisk /dev/vdb       t for type; b for W95 FAT32
sudo mkfs.vfat /dev/vdb1      up to 2GB in size
sudo mkfs.vfat -F 32 /dev/vdb1     2GB or larger size, up to 16TB with 4096 byte per sector

sudo mkdir /myvfat
sudo mount /dev/vdb1 /myvfat/
sudo vi /etc/fstab
      /dev/vdb1 /myvfat vfat defaults 0 0
sudo umount /myvfat/


================================================================= Autofs    NFS

in the server create a directory which can be shared with other hosts when connected to the server, if you wnat to share more files
just add in that directory, then it will be visible for other hosts using NFS.
NFS shared dir are not permanently connected
the automounter is configured on the client machine
NFS shares are available to all users

autofs service can mount/unmount file systems automatically (on-demand), which saves system resources. /etc/fstab even you dont mount the system must keep
resources in case you want mount. That is not ideal.

sudo yum -y install autofs
systemctl start autofs
vi /etc/auto.master

mount automatically NFS on host example at /automount directory
<IP>:/public & <IP>:.private
public NFS should have read only access for all users
private NFS should have read and write access for all users
both shares should get automatically unmounted if not in use for 30seconds

1- yum install -y nfs*
2 - yum install -y autofs
3 - mkdir -p /automount/private
4 - mkdir -p /automount/public
5 - sudo vi /etc/auto.master    #end of the file add /automount /etc/automount.txt --timeout=30
6 - sudo vi /etc/automount      public -ro,sync <IP>:/public    private -rw,sync <IP>:/private
7 - sudo showmount -e <IP>      # need to enable rpcbind client before to use this command
8 - systemctl enable autofs
9 - systemctl enable rpcbind
10 - df -h

----------------- EXAMPLE 
##in the server##
yum install nfs*
mkdir /share
touch /share/file1 /share/file2
chmod 777 /share
vi /etc/exports
  /share <IPhost1> <IPhost2>(ro,sync) 
exportfs -avr
firewall-cmd --add-service=(nfs.mountd.rpc-bind) --permanent
firewall-cmd --reload

##for the client/host##
yum install nfs-utils 
yum install autofs
showmount -e <IPserver>    #check which nfs volume is available 
vi /etc/auto.master
    comment #/misc /etc/auto.misc
    add     /auto_mount /etc/auto.misc --timeout=30    (you dont need to specify the timeout if you dont want)
vi /etc/auto.misc 
    add     access   -rw,soft,intr    <IPserver>:/share
systemctl enable autofs --now
ls /    # verify the auto_mount
    


================================================================== Configure systems to mount file systems at or during boot

It instructs the operating system that filesystem is ready to use and associate it with a particular point in the system's hierarchy. 
Mounting will make files, directories and devices available to the users.
The mount command is used to make a device or file system accessible to the system, and then to connect 
its root directory to a mount point on the local file system.


the files can be accesible we must first mount
first look at a dir often used for temporarily mounting random filesystem
  ls /mnt/

to mount we use
sudo mount /dev/vdb1 /mnt/

with the file system mounted then we can create file on it
sudo touch /mnt/testfile

to see the block is mounted
lsblk

to unmount a file system use
sudo umount /mnt/

--------------------------------------------------------    /etc/fstab

 The fstab file typically lists all available disks and disk partitions, and indicates 
 how they are to be initialized or otherwise integrated into the overall system's file system


/dev/mapper/cs-root   /   xfs   defaults  0   0
1 - tell linux to mount the file system contained in the partition
2 - specify the mount point
3 - filesystem type
4 - mount options
5 - tell the utility dump should back up the files (0 is disabled; 1 enabled) - it is not used nowadays
6 - decide what to do when errors are detected  (0 filesystem shoud never be scanned for erros; 1 scan first for errors before - root filesystem
; 2 scan after scan number 1 - other filesystems, like /dev/vdc (this filesystem should be checked on boot))

man fstab

sudo vim /etc/fstab
/dev/vdb1/    /mybackups    xfs   defaults 0  2

sudo systemctl daemon-reload

mount swap partition when boot up
sudo vim /etc/fstab
/dev/mapper/cs-swap    none    swap   defaults 0  0
/dev/vdb3   none      swap    defaults 0 0 


you can use UUID, to avoid connect the storages in diferent connectors on motherboard, instead to use in fstab /dev/vdb1/
you can check the uuid in
sudo blkid /dev/vdb1



=================================================================     Configure disk compression 

Virtual Data Optimizer (VDO) is a block virtualization technology that provides transparent deduplication of data. 
By eliminating redundant chunks of data, VDO can greatly reduce actual used disk capacity.

virtual data optimizer - VDO
helps with zero-block filtering; deduplication and compression

zero-block filtering -look all the block and filters out block that contain only zeros (no data)

deduplication - video check if data has been written to the disc already in another place

compression - compress the data and packed together to save space on the disk


yum install vdo kmod-kvdo

sudo systemctl enable --now vdo

sudo vdo create --name=vdo_storage --device=/dev/vdb --vdoLogicalSize=10G

sudo vdostats --human-readable

sudo mkfs.xfs -K /dev/mapper/vdo_storage  

sudo udevadm settle

sudo vdostats --human-readable

mount vdo devices

sudo mkdir /mnt/myvdo

sudo vi /etc/fstab
      /dev/mapper/vdo_storage       /mnt/myvdo        xfs   _netdev,x-systemd.device-timeout=0,x-systemd.requires=vdo.service 0 0
       _netdev,x-systemd.device-timeout=0,x-systemd.requires=vdo.service  -> mount options are required for all video devices to be mounted
       at boot time, the service needs to be load before the device can be mounted again.

df -h /mnt/myvdo

-----------------------------------------------------------  saving space with VDO 

Virtual Data Optimizer (VDO) is a block virtualization technology that provides transparent deduplication of data. 
By eliminating redundant chunks of data, VDO can greatly reduce actual used disk capacity.


rhel9  
sudo pvcreate /dev/vdb
sudo vgcreate vdo_volume /dev/vdb
sudo lvcreate --type vdo -n vdo_storage -L 100%FREE -V 10G vdo_volume/vdo_pool1
sudo mkfs.xfs -K /dev/vdo_volume/vdo_storage     OR     sudo mkfs.ext4 -E nodiscard /dev/vdo_volume/vdo_storage 


mounting lvmvdo devices

manlvmvdo
sudo mkdir /mnt/myvdo
sudo vi /etc/fstab
                   /dev/vdo_volume/vdo_storage       /mnt/myvdo        xfs   defaults    0 0
sudo mount -a
df -h /mnt/myvdo


=======================================================================   Manage layered storage 

Stratis is a local storage management tool. Manages pools of physical storage, helps simplify storage management
central component of Stratis is the storage pool, they are created from one or more disks or partitions, after created volumes can be
created on top of that

stratis is similar to lvm, but is easier to configure, deploy and manage
XFS file system
dont use XFS tools to manage stratis filesystem

sudo yum install stratisd stratis-cli

sudo systemctl enable --now stratisd.service

sudo stratis pool create my-pool /dev/vdc
can use one more block  just specify in the command 
sudo stratis pool create my-pool /dev/vdc /dev/vdd

sudo stratis pool list              
sudo stratis blockdev

create a filesystem
sudo stratis fs create my-pool myfs1                  myfs1 is the filesystem create on top of the pool
sudo stratis fs create developers devfs               one example to create fs on top of the developers pool
sudo stratis fs

sudo mkdir /mnt/mystratis
sudo vi /etc/fstab 
            /dev/stratis/my-pool/myfs1  /mnt/mystratis      xfs   x-systemd.requires=stratisd.service  0   0
            /dev/stratis/developers/devfs /mnt/devstorage xfs x-systemd.requires=stratisd.service 0 0

/dev/stratis/developers/devfs         Can be seeing using the command sudo stratis fs

sudo mount -a
sudo cp /home/username/file /mnt/mystratis

to add storage
sudo stratis pool add-data my-pool /dev/vdd
sudo stratis pool

filesystem snapshots
sudo stratis fs snapshot my-pool myfs1 myfs1-snapshot
sudo stratis fs snapshot developers devfs devfs-snapshot
sudo stratis fs   to check the snapshot

to recover from snapshot
rename the current statis file system 
sudo stratis fs rename my-pool myfs1 myfs1-old         sudo stratis fs rename developers devfs devfs-bad (another example)
next rename the snapshot to use the original filesystem name
sudo stratis fs rename my-pool myfs1-snapshot myfs1
sudo umount /mnt/mystratis
sudo mount /mnt/mystratis




====================================              Deploy, Configure, and Maintain Systems                ================================================


----------------------------------------------------------------------   CRONTAB  

cat /etc/crontab 
  can use  ',' this it will run multiple times like 15min and 45minutes -> 15,45
  can use '-', set hours to 2-4 2am,3am,4am
  can use '/', to specifies steps, every 4hours it will run. */3 * * * * ->execute every 3min
  Minute(0-59) Hour(0-23) Day_of_month(1-31) Month(1-12) Day_of_week(0-6) [Sunday=0 or 7] or sun,mon,tue,wed,thu,fri,sat
  
check the service is running in the machine
service cron status
service cron start

crontab -e 
  edit he table of youyr current user
  
crontab -l   - to see user logged in cronjobs

to edit as sudo just add sudo at the front
sudo crontab -l       list
sudo crontab -e       edit
30 21 * * * /usr/bin/touch test_passed

to add with different user
sudo crontab -e -u <username>

to remove cronjob
crontab -r
sudo crontab -r -u <username>

to run a sheel script in a cronjob dont add extension
makes executable
sudo chmod +rx /etc/cron.hourly/shellscript
if want run hourly (/etc/cron.hourly) just move to this dir, using sudo 

check the logs
sudo cat /var/log/cron

to send an email to user change the MAILTO=root

to deny user to do cronjob
/etc/cron.deny      #ype the name user in the file and save
to verify login with the user and try to use the command crontab -e


---------------------------------------------------------   Scheduling jobs with anacron 

using anacron we dont care the time the job is going to run, just want to run daily, hourly,...

to add a job need to edit the file
sudo vim /etc/anacrontab

run once every 10 days
have 5 minutes of delay
the job id should be db_cleanup
command to run is: /usr/bin/touch /root/anacron_created_this

10 5 db_cleanup /usr/bin/touch /root/anacron_created_this


can use anacron -T  to test the job

sudo vim /etc/anacrontab

to run the jobs right now, to rerun all jobs, regardless of when they were last executed
sudo anacron -n -f

check the logs, analyse to see if anacron jobs have successfully ran
sudo grep anacron /var/log/cron


------------------------------------------------------   Scheduling jobs with at 
just specify the time

at 15:00
at> /usr/bin/touch  file
ctrl +d to save the job

at 'December 01 2020'
at '1:30 December 01 2020'
at 'now + 30 minutes'     in 30 minutes from now

atq               to see the jobs, command to see the jobs that are scheduled to run in at utility
at -c <job_id>    to see what the jobs does

atrm <job_id>     to remove the job


sing root user, schedule below given command to run at 15:30 August 20 2024 by using at utility:
/usr/bin/touch atscheduler
Switch to the root user using sudo -i command, then execute command at '15:30 August 20 2024'
Add /usr/bin/touch atscheduler line, enter,   then save it by pressing CTRL+D


============================================================        Manage the startup process and services 

units - services, socket, device, timer
units tells the init system all it needs to know about how it should manage the entire life cycle of certain app

man systemd.service

systemctl cat sshd.service
execstart
execreload
those command tells the init which command should run

sudo systemctl edit --full sshd.service

when change the config use 
sudo systemctl restart sshd.service
but if a user is using that service may interrupt their work temporarily, better way is to use (not all service can use reload)
sudo systemctl reload sshd.service
sudo systemctl reload-or-restart sshd.service
daemon-reload is a reload for systemd, while reload is a reload for a specific service

mask a service
When you mask a service, it cannot be started manually. In other words, masking a service renders the service permanently unusable until it's unmasked.
A masked service is one whose unit file is a symlink to /dev/null . This makes it "impossible" to load the service, even if it is required by another, enabled service.

sometimes services start even there are disabled and stopped
to force brute stop
sudo systemctl mask atd.service    when you mask a service when you enable it wont work, need unmask
sudo systemctl unmask atd.service

to list services available on the system
sudo systemctl list-units --type service --all

systemctl is-enabled httpd          command to check the service is enable/disable


=========================================  Install and update software packages from Red Hat Network, a remote repository, or from the local file system

package manager - dnf, yum

list of which repo are currently enabled on the server/host
sudo yum repolist
sudo yum repolist -v    get a list of online repo, that your system is currently using 

sometimes the default repo dont include what we are looking for 
to list the optionals repo
sudo yum repolist --all
sudo subscription-manager repos --enable <repo.rpms>
sudo yum-config-manager --enable <repo.rpms>

if we dont find the repo we want and want add other repo
use the yum conf manager
first install this utilities
sudo yum install yum-utils    this contains yum manager
sudo yum-config-manager --add-repo <website.repo>       add the repo online
sudo yum-config-manager --add-repo <IP/Repo.repo>       add the repo local
    with that will create /etc/yum.repos.d/<repo>.repo


sudo vi  /etc/yum.repos.d/<repo>.repo
[base]    ->name of the repo
name=CentOS-$releasever - Base      -> long name for the repo
mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os&infra=$infra
#baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/      ->tells where the repo is located, can be local or  in the internet
enabled = 1         -> 1 means available for use 
gpgcheck=1          -> check the validity of the package using gpg keys
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7     ->where is the gpg located

Create a yum repo file located at /etc/yum.repos.d/kodekloud.repo as per details given below:
short name: KodeKloud
long name: KodeKloud -
baseurl: https://repos.kodekloud.com/linux/$releasever/$basearch/development
Also make sure it is set to be enabled

sudo vi /etc/yum.repos.d/kodekloud.repo           - this looks like /etc/yum.repos.d/CentOS-Stream-BaseOS.repo
[KodeKloud]
name=KodeKloud - $basearch
baseurl=https://repos.kodekloud.com/linux/$releasever/$basearch/development
enabled=1

need to add a file vi /etc/yum.repos.d/local.repo
[baseos]
name=BaseOS
baseurl=http://example.com
gpgcheck=0
enabled=1

[appstream]
name=AppStream
baseurl=http://example.com
gpgcheck=0
enabled=1


yum can also used to install and uninstall individual packages from repo
for that we need to know the name of the package, if you dont know can use yum to look for it
ex.: sudo yum search web server
sudo yum search 'web server'

sudo yum info <package>

sudo yum install <package>

sudo yum reinstall <package>
 
sudo yum remove <package>

to install packages in a certain group
sudo yum group list
sudo yum group list --hidden               display all of the possible package groups, including those that are hidden
sudo yum group install '<groupname>'

yum can install software from rpm packages
sudo wget https://package.rpm
sudo yum install <./package.rpm>
sudo yum remove <package_name>

sometimes packages pull in dependencies which are ohte components that they need to run correctly
when remove the package  some of those dependencies might be left behind
to make sure that remove automatically all dependencies after removed the package
sudo yum autoremove

update and upgrade packages
sudo yum check-upgrade  check which package needs an update
sudo yum update     to update all packages to the latest version

--------------------------------------------------------------------- WORKING WITH PACKAGES MODULES STREAM   

stream allow to designate multiple versions of software packages to group together as modules
give greater flexibility and compatibility options
module is a set of packages that normally get installed together

available modules
sudo yum module list
sudo yum module list <service>

install
sudo yum module  install nodejs
sudo yum module list --installed nodejs


different version  (/name-of-profile), can get the name in module list
sudo yum install module nodejs:14/development

to change the module 
sudo yum module reset nodejs
sudo yum module  install nodejs:16/development
sudo yum module install php:8.0/minimal -y                                install the version 8.0 of the php module using the minimal profile

Reset the module stream for the container-tools package as below:
sudo yum -y module reset container-tools
Then use yum to install version 3.0 of the container-tools package with below command:

sudo yum -y module install container-tools:3.0 --skip-broken --allowerasing --nobest



====================================       Configure networking and hostname resolution statically or dynamically          =====================================
 


if the host need to access the internet, it will need a gateway and DNS.
Host wants to access google, it will ask DNS resolver what is the IP addr for google, then
DNS gives the IP-google so the host can connect to the google. Now the host can talk to the gateway
like I want this data to reach to IP-google, then the gateway sends it out from our network
to another network until reach the destination

dynamically  settings are from a service like DHCP
manually we need to set up the IP

first look for the name of the network
ip link show      OR      ip l
output it will be sometime like
enp0s3:....

different network interface, with more info
ip addresses show    OR    ip a
enp0s3:....
inet IPv4

network cards that use wire start with letter E, wirelless with W 

IPv4 - 32bits
IPv6 - 128bits

routing table
ip route show     OR    ip r
ip addr via default gateway
the output it will something like
default via 192.168.1.1 dev enp0s3 ...
the default getway it will be what is show above

Identify the default gateway on this system below.               The gateway it will be 172.25.0.1
ip route
default via 172.25.0.1 dev eth1 
172.25.0.0/24 dev eth1 proto kernel scope link src 172.25.0.69 
192.15.56.0/24 dev eth0 proto kernel scope link src 192.15.56.9 
192.168.122.0/24 dev virbr0 proto kernel scope link src 192.168.122.1 linkdown

add an extra IP to eth1 interface on this system: 10.0.0.50/24
sudo ip a add 10.0.0.50/24 dev eth1

to see the DNS that the system is currently using
/etc/resolv.conf
the output it will something like
nameserver 192.168.1.1

nameserver it will be always a valid DNS resolver, it is normal see two or more listed here,
those are for backups

Configure static resolution so that example.com hostname resolves to IP address 8.8.8.8
static DNS
sudo /etc/hosts


centOS it will configure waht is inside this file
/etc/sysconfig/network-scripts/
inside the file you see the different network adapter, choose one and it will show
BOOTPROTO=dhcp
this means it is auto configured
for static change dhcp for none
 in RH distros a program called network manager is the default or managing anything.
 
 2 usefull tools network manager has

 nmtui - network manager text user interface
 usually is installed by default, if not use dnf package
 sudo nmtui
 it will show another window wher eyou can configure the network inteface
 configure the DNS, Gateway, IPv4 + subnet if you choose manually
 to apply the configuration reboot or
 sudo nmcli device reapply enps03
 
 
 --------------------- 2 ways to configure
 
 Configure sets
 ipv4 192.168.122.10
 subnet mask: 255.255.255.0
 default gateway: 192.168.122.1
 dns server: 192.168.100.1
 interface name: enp1s0
 
1 - 
nmtui. Edit connection and fill up the gap, dont forget to actived 
2 - 
nmcli connection add type ethernet con-name eth0 ifname enp1s0 ipv4.addresses 192.168.122.11/24 ipv4.gateway 192.168.122.1 ipv4.dns
192.168.100.1 method manual connection.autoconnect yes
3-

 
==============================================================    Configure network services to start automatically at boot 
 
 if the network manager is not working it wont have ips, gateways and so on
 check the network manager, mus be enabled
 systemctl status NetworkManager.service
 
 to install
 dnf install NetworkManager
 
 
 another way to enable nmcli at boot is 
 nmcli connection show  (take note of the name connection)
 sudo nmcli connection modify <name=enp0s3> auto connect yes



==============================================================   Start, stop, and check the status of network services
SS  - modern tool
Netstat
 
list of all incoming open ports on this system
sudo ss -tulnp | grep LISTEN 
sudo netstat -tulpn | grep LISTEN
 
How do we see what processes on our system are listening for incoming network connections, on the TCP and UDP protocols?
sudo ss -tunlp

sudo ss -tunlp  
-l : listening means ready to accept an incoming connection
-t : tcp connections
-u : udp connections
-n: numeric values, we get port number
-p: processes is envolved, with p flag needs sudo priv

ss -ltun    without p it will show the service name instead of port number

the output will have some 
Netid  State    Recv-Q   Send-Q     Local Address:Port      Peer Address:Port  Process                                                                        
udp    UNCONN   0        0          127.0.0.1:323             0.0.0.0:*      users:(("chronyd",pid=684,fd=13))                                     
udp    UNCONN   0        0                0.0.0.0:22            0.0.0.0:*      users:(("ssh",pid=1249,fd=7))                                                                              
udp    UNCONN   0        0                   [::]:53198             [::]:*      users:(("avahi-daemon",pid=921,fd=15))                                        
tcp    LISTEN   0        128                [::1]:631               [::]:*      users:(("cupsd",pid=1092,fd=6))    

127.0.0.1:323  - the program is listning for incoming connections from the system itself, but no from other computers
0.0.0.0:22  - it will accept connections from any external IP addr
[::]:53198 - this means same as 0.0.0.0, but listening for connections from IPv6
[::1]:631 - this means same as 127.0.0.1, but listening for connections from IPv6

Find out what process is listening for incoming connections on port 22
#
sudo ss -tulnp | grep :22

in this table you can see the PID, with that we can check the pid and the files that are open by this process
ps  <pid>
sudo lsof -p <pid>



====================================================================   Implement packet filtering 


with a firewall added to the system will filter out what network packets are allowed to come into our system and even what network packets are 
allowed to go out

red hat has firewalld
the firewall manager puts every network interface in zones, each zones has own rules
zone drop is very restrictive and blocks all incoming connections
zone trusted - all connections are accepted, for example in a office you ccepted all those incoming connections

the default zone is public, every incoming connection is blocked, except  what we allow
check the zone 
firewall-cmd --get-default-zone

change the zone
firewall-cmd --set-default-zone=public

to see current firewall rules
sudo firewall-cmd --list-all
 the output it will show the cockpit, where you can use a command to check the port are listening for the service cockpit
sudo firewall-cmd --info-service=cockpit 
 the output it will show the cockpit servie allow incoming connections to port example 9595 through a tcp protocol
 
to allow traffic can be both
sudo firewall-cmd --add-service=http   OR    sudo firewall-cmd --add-port=80/tcp

then if you check the list, it will add a new rule in front of the cockpit
sudo firewall-cmd --list-all

to remove
sudo firewall-cmd --remove-service=http    OR    sudo firewall-cmd --remove-port=80/tcp

instead to block all incoming traffic, can use different rule based on where the traffic is coming from
sudo firewall-cmd --add-source=10.11.12.0/24 --zone=trusted

block
sudo firewall-cmd --add-source=10.11.12.0/24 --zone=block --permanent 
sudo firewall-cmd --reload
sudo firewall-cmd --zone=block --list-all    #verify

check active zones
firewall-cmd --get-active-zones

Allow all traffic that is coming from any IP in this network range: 10.11.12.0 to 10.11.12.255 (i.e 10.11.12.0/24), 
add the required rule in the trusted zone and the rule must be permanent.
#
sudo firewall-cmd --add-source=10.11.12.0/24 --zone=trusted --permanent

remove filter based on ip addr
sudo firewall-cmd --remove-source=10.11.12.0/24 --zone=trusted

all the rules set above are no permanent if reboot the rules will be lost, to keep permanent does those commands below
sudo firewall-cmd --add-port=123/tcp                                                                              add
sudo firewall-cmd --list-all                                                                                      check
sudo firewall-cmd --runtime-to-permanent       OR       sudo firewall-cmd --add-port=123/tcp --permanent          permanent


===================================================================   Statically route IP traffic 


it is good to specify the IP of your won machine
sudo ip route add 192.168.0.0/24 via 10.11.12.100 dev enp0s3   dev-device name; enp0s3 is the name of interface
sudo ip route add default via 10.0.0.100         gateway, if you you want to rech at 1.2.3.8 routing table is consulted and if no specific route is found
then this data packet iis sent to the default route which is 10.0.0.100

Temporarily route all traffic that must reach the 192.168.0.* network through the device that has the IP 172.28.128.100
sudo ip route add 192.168.0.0/24 via 172.28.128.100
ip route
192.168.0.0/24 via 172.28.128.100 dev eth1 
permanently route all traffic
sudo nmcli connection modify eth1 +ipv4.routes "192.168.0.0/24 172.28.128.100"
sudo nmcli device reapply eth1


add an extra IP to eth1 interface on this system: 10.0.0.50/24
sudo ip a add 10.0.0.50/24 dev eth1
Re-apply network settings
sudo nmcli device reapply eth1


to delete
sudo ip route del 192.168.0.0/24
sudo ip route del via 10.0.0.100

those routes added this way are temporary, to make permanent
nmcli connection show
nmcli connection modify <enp0s3> +ipv4.routes "192.168.0.0/24 10.0.0.100" 
this means if you want to reach to 192.168.0.0/24 route all traffic through the device 10.0.0.100
sudo nmcli device reapply <enp0s3>

to confirm
ip route show

to remove
home nmcli connection modify <enp0s3> -ipv4.routes "192.168.0.0/24 10.0.0.100"    use the - (minus)

you can use the tool 
sudo nmtui
sudo nmcli device reapply <enp0s3>


-----------------------  ################### Important

To create a connection is good to use nmcli, to edit it will be easier to use nmtui (for nmcli it will be nmcli con mod)

Parameters
con-name    #connection name
type
ifname      #interface name
autoconnect
ip4
gw4

nmcli con show                                              #view the connections
nmcli con show eth0                                         #show all the parameters

nmcli con add con-name <connection-name> type <ethernet> ifname <ens160> ipv4 <IP/MASK> gw4 <IP>

nmcli con up <connection-name>

autoconnect    #after reboot it will autoconnect with the interface you set up
nmcli con mod <connection-name> connection.autoconnect yes
    
nmcli con mod <connection-name> ipv4.addresses <newIP/MASK>

#to add DNS need to use nmcli con mod
nmcli con mod <connection-name> ipv4.dns <IP>

# to assign more IP to a connection
nmcli con mod <connection-name> +ipv4.addresses <IP/MASK>

=========================================================================  Configure time service clients  - NTP (Network Time Protocol)

sudo yum install chrony
sudo vi /etc/chrony.conf    server <ip> iburst    and comment  #pool 2.centos.pool.ntp.org iburst
systemctl restart chronyd
chronyc sources -v  
sudo systemctl set-ntp true

keep the clock accurate
chrony daemon 

to see it is enable
systemctl status chronyd.service

run this command to check the system clock is synchronized
timedatectl

timedatectl list-timezones 
timedatectl list-timezones | grep America 

if is not enable by default first check if the time zone is set correctly
sudo timedatectl set-timezone America/New_York          to see all available zones timedatectl list-timezones
sudo dnf install chrony
sudo sysstemctl start chronyd.service
sudo sysstemctl enable chronyd.service
then check the ntp is enable and system clock is synch using the command
timedatectl
in case is not enable
sudo systemctl set-ntp true
 

Using timedatectl configure RTC (real-time clock) to maintain the RTC in local time.
RTC is a battery-powered computer clock that keeps track of the time even when the system is turned off.
sudo timedatectl set-local-rtc 1



==========================================        Manage Users and Groups     ======================================================


Create, delete, and modify local user accounts ===========================================================================

sudo useradd <username>
it will automatically create user and group with the username, also a shell and a home dir
sudo useradd --shell /bin/othershell --home-dir /home/otherdirectory/ john

useradd --defaults   OR  useradd -D

another defaults configurations can be seen in
cat /etc/login.defs

setup a password
sudo passwd <username>

delete acc and group. Home dir it will remain
sudo userdel <username>

delete acc and the home dir
sudo userdel --remove john   OR      sudo userdel -r john

delete a groupd
sudo groupdel <groupname>

to choose id for the user
sudo useradd --uid 1100 <username>

to check the id numbers and home dir
ls -ln /home

id
check group, userid and so on

create system account
sudo useradd --system <systemname>
those numbers are smaller than 1000
usually daemon use system accs

with want to change conf after create user
sudo usermod --home /home/otherdir --move-home john   OR    sudo usermod -d /home/otherdir -n john
sudo usermod --login <new_username> <old_username>    OR    sudo usermod -l <new_username> <old_username>
sudo usermod --shell /home/otherdir <username>        OR    sudo usermod -s /home/otherdir <username>

disable the acc. Lock the user account
sudo usermod --lock <username>    OR sudo usermod -L <username>       
username cannot login even using the password, but can login using ssh if was set up before lock
to avoid that set up a expire date
sudo usermod --expiredate 2020-12-20 <username>     if you want to set up now, just choose a date in the past
to remove expiry date 
sudo usermod --expiredate "" <username> 

password for all new users in domain.com should expire after 20 days
vi /etc/login.defs
PASS_MAX_DAYS 20

check the user acc regarding expiration
#
sudo chage -l <username>

to set up an expiration date for password. This command set expired password and the user are force to immediately change it the next time logs in
sudo chage --lastday 0 <username>

to cancel expiration date for password
sudo chage --lastday -1 <username>

to set up a date for user change the password
sudo chage --maxdays 30 <username>

set up for password never expiry
sudo chage --maxdays -1 <username>

to see the list for password expires
sudo chage --list <username>

User gets a warning at least 2 days before the password expires
sudo chage -W 2 <username>


Create, delete, and modify local groups and group memberships ===========================================================================

sudo groupadd developers

add user to a group
sudo gpasswd --add <usrname> <developers>

to see which group the user belongs to
groups <username>

delete a user to a group
sudo gpasswd --delete <username> <developers>

change the primary group of the user
sudo usermod -g <developers> <username>     OR   sudo usermod --gid <developers> <username>
the capital G flag is to change the secondary group

group named cricket and set its GID to 9875
sudo groupadd -g 9875 cricket 

to rename the group
sudo groupmod --new-name <nem_name> <old_name>

to delete a grooup
sudo groupdel <groupname>


Manage access to the root account  ==========================================================================================================

login as a root, when the user has sudo priv
sudo --login   OR  sudo -i

when the user doesnt have sudo priv, but knows root password
su -  

some system they have root locked, means we cannot login with root acc only with the password
we can login using sudo -i, but not su -
also can login using ssh private key

to unlock use
sudo passwd root   OR   sudo passwd --unlock root

to lock root acc, avoid using password
sudo passwd --lock root

change the root password
sudo passwd



Configure PAM ============================================================================================================================

PAM - Pluggable authentication module
allows a Linux system administrator to configure methods to authenticate users.

plugable authentication module
this gives us flexibility about how we want certain utilities to perform authentication on our system

best way is to -> man pam.conf
manuals for all pam modules -> man pam (press TAB twice)

/etc/pam.d/ -> this is the file that defines the plugable auth modules that should be used by the su, for example
there will see alot utilities, to edit use vi, then you just need uncomment to add an extra ayth module

for the su utility so that this utility only accepts the requests from users that are part of the wheel group
sudo vi /etc/pam.d/su
Uncomment below given line:
#auth           required        pam_wheel.so use_uid

su utility so that the requests from the users that are the member of the wheel group should be accepted immediately, without asking for any password
sudo vi /etc/pam.d/su
Uncomment below given line:
#auth           sufficient      pam_wheel.so trust use_uid

Restrict the root access to SSH service via PAM
sudo vi /etc/pam.d/sshd
Add below given line at the end of the file and save it:
auth    required       pam_listfile.so onerr=succeed  item=user  sense=deny  file=/etc/ssh/deniedusers
Now create /etc/ssh/deniedusers file
sudo vi /etc/ssh/deniedusers
Add root user in the file, so its content should look like this:
root
Finally save the changes



=========================================          Manage Security                    =========================================

---------------------------------------------- configuring SSH servers and clients

yum install openssh-server   #install in both machines

configuration file /etc/ssh/sshd_config (sshd -> the D means daemon) man sshd_config /etc/ssh/ssh_config (this is the config file for client, no D)

/etc/ssh/sshd_config can change the port number can change the AddressFamily, this can change for ipv4, ipv6 or both 
(look at man page and search for Family) can change ListernAddress, so you can specify a IP addr to listen can change PermitRootLogin, 
this case you can login as a root using ssh service can change the PasswordAuthentication, this case choosen no, only ssh keys it will be 
possible to login can change the x11forwarding - start a remote app and forwarding to you local machine to interact

For example disable passwordauthentication global, but if you want do an exemption for an user add below 
PasswordAuthentication Match User PasswordAuthentication yes

After change need to reload to apply the new changes sudo systemctl reload sshd.service

For the client we can add a file under ~/.ssh/config, change the permission chmod 600 config inside this file
we can add host with informations Host centos Hostname Port 22 User

then you can use only ssh centos to access the host/server

To use ssh keys, generate keys in the client 
#
ssh-keygen

then copy the public key to the server 
#
ssh-copy-id username@IP

to remove fingerprint from a specific server saved in the known host 
#
ssh-keygen -R

when you login using ssh, the client has some default config file 
/etc/ss/ssh_config this is not a good practice to make change in this file because 
future upgrade of the ssh client it might overwrite the changes, 
better way is to modify in /etc/ssh/ssh_config.d/<name_of_conf_file> then you can add new port, for example

Edit the system-wide configuration of the SSH client and turn on X11 forwarding
sudo vi /etc/ssh/ssh_config
Uncomment below given line or add it if doesn't exist:
ForwardX11 yes

Squid proxy daemon. Add a src type acl and name it vpn. The IP you should use in this acl is 203.0.110.5. 
Now add a new rule that tells the proxy server to allow access to the acl named vpn.
sudo vi /etc/squid/squid.conf
acl vpn src 203.0.110.5
Add below given line in the same file before http_access deny all
http_access allow vpn

 SSH server and configure it to use only IPv4 IP address family
 AddressFamily inet
 
Squid proxy daemon. Now add a new rule that allow http access to the external
sudo vi /etc/squid/squid.conf
Add below given line in this file after http_access allow localhost line:
http_access allow external  

Squid proxy daemon , add an acl and http access rule to block facebook.com
acl facebook dstdomain .facebook.com
And add below given line after http_access allow localhost line:
http_access deny facebook
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
http_access deny facebook


======================================================================  List and Identify SELinux file and process contexts 


linux kernel can be easily extended with so-called modules, one of them is SELinux that add variant advanced capabilities of restricting access 
SELinux is enable by defaut by centos

collections of rules go on which process have access to which file directly or port

ls -Z drwxr-xr-x. devops devops unconfined_u:object_r:user_home_t:s0 Desktop

unconfined_u:object_r:user_home_t:s0 ->string is called SElabel or SElinux context 
unconfined_u - user 
object_r - role 
user_home_t - type 
s0 - level

only certain users can enter certains roles and certain types lets authorized users and processes do their job, 
by grating the permissions they need authorized users and processes are allowed to take only a limited set of actions everything else is denied

ps axZ

to see the security context assigned to the current user. What got applied to our user when we logged in you can use: id -Z

dnf install -y policycoreutils*    this is to install SEMANAGE
dnf provides semanage             can see the packages

when we log in the user we log in as is automatically map to an SELinux user 
To see this mapping is done sudo semanage login -l sudo semanage user -l - > group
Identify the SELinux Roles for xguest_u SELinux
sudo semanage user -l

to check the ports
sudo semanage port -l
semanage port -l | grep http

to see the SELinux is actively restricting actions getenforce the output it must be 
Enforcing if is Disabled is not doing anything if it is Permissive means it is allowing everything and locking actions that
should have been restricted instead of denying


Example 
Configure SELinux for webcontent configured in port 80 at /var/www/html. Make content accessible
1- install http and enable
2 - dnf install -y policycoreutils*
3 - semanage port -l | grep http      #save the output http_port_t
4 - semanage port -a -t http_port_t -p tcp 82
5 - firewall-cmd --permanent --add-port=82/tcp
6 - firewall-cmd reload
7 - firewall-cmd --list-all    #verify the rules
8 - vi /etc/httpd/conf/httpd.conf    #search for Listen and change the port number to 82
9 - sudo systemctl restart httpd
10 - curl http://<IP>:82


-----------------
collections of rules go on which process have access to which file directly or port

dnf install -y policycoreutils*

Change the SELinux context of /var/index.html file to httpd_sys_content_t
sudo chcon -t httpd_sys_content_t /var/index.html            #Temporary Changes: chcon
semanage fcontext -a -t  httpd_sys_content_t "/var(/.*)?"

sudo semanage fcontext --list | grep http                     # list all the context

Set the appropriate context for all files in the /kodekloud/ directory:
semanage fcontext -a -t httpd_sys_content_t "/kodekloud(/.*)?"
restorecon -Rv /kodekloud                             #restorecon utility apply the context changes

Temporarily change the SELinux status to Permissive on this system
sudo setenforce 0 (permissive) it wont restrict but it will report/monitoring
sudo setenforce 1 (enforcing)  it will restrict the access

# to keep persistent vi /etc/selinux/config or /etc/sysconfig/selinux 
SELINUX=Permissive   (edit this line)

Restore the correct contexts:
restorecon -R /kodekloud/

change booleans           # in doubt do sudo semanage boolean --help
sudo semanage boolean -l | grep httpd_enable
sudo semanage boolean -m httpd_enable_homedirs -1

to make persistent change   - setsebool boolean_name on/off
sudo semanage boolean -l | grep httpd
setsebool -P httpd_can_network_connect_db on


----------- examples

dnf install -y policycoreutils*

1 - ensure httpd is able to access the user home dir   # need to change the boolean
setsebool -P httpd_enable_homedirs on

2- system not able to connect to httpd service port 82.     # need to change the port, check firewall as well
semanage port -l | grep http
semanage port -a -t http_port_t -p tcp 82

3 - ensure the httpd service is able to access and host files grom the /test directory    # change the context
check the context in 
    ls /var/www/html/index.html
    curl localhost/index.html   # verify it is working
mkdir /test
touch /test/index.html
check the context in 
     ls -lZ /test
semanage fcontext -a -t http_sys_content_t "/test(/.*)?"   
restorecon -Rv /test
ls -lZ /test

vi /etc/httpd/conf/httpd.conf
DocumentRoot "/test"
<Directory "test">

systemctl restart httpd

curl localhost/index.html

-------------------------------------------------------------------------------------------------

SELinux context label for the sshd process
#
check the PID for the process
systemctl status <service>
ps -el | grep <service>

ps -Z <service_PID>


current SELinux mode on the system
#
getenforce

Temporarily change the SELinux status to Permissive on this system
sudo setenforce 0 (permissive) it wont restrict but it will report
sudo setenforce 1 (enforcing)  it will restrict the access

# to keep persistent vi /etc/selinux/config
SELINUX=Permissive   (edit this line)


===========================================================  Change kernel runtime parameters, persistent and non-persistent 


kernel runtime parameters is what the linux kernel does its job internally kernel deals with low level stop like allocating memory, 
handling network traffic and so on. Most of those settings involve those types of things. 
To see all kernel runtime parameters currently in use sudo sysctl -a

to change the values, for example ipv6. sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1 this change is not persistent

to make a change persistent /etc/sysctl.d/*.conf 
sudo vi /etc/sysctl.conf

to immediately set up the changes use sudo sysctl -p /etc/sysctl.d/<swap-less.conf>   OR sudo systcl -p

Turn on kernel.modules_disabled kernel runtime parameter, so that loading new kernel modules will be disabled
sudo sysctl -w kernel.modules_disabled=1

Adjust the value of this kernel runtime parameter, vm.swappiness, to 10.
After you set this to 10, also make the change persistent so that it will be auto-set to this value on the next reboot.
sudo vi /etc/sysctl.conf
Add below given code in this file and save it:
vm.swappiness=10
Apply the changes:
sudo sysctl -p


 ===================================================================   Restore default file contexts


Using booleans values to modify settings of boot time, stop the boot process

can add enforcing=0 ; this cause the system to boot into permissive mode for SELinux

Which of the following GRUB command line options would cause a Linux system to boot with SELinux disabled
selinux=0
If a system is booted with the GRUB command line option selinux=0, 
the next time the system is booted without this command line option, the system will force an autorelabel

selinux=0 ; the kernel wont load anything to SELinux and the next time the system gets booted without that parameter 
it is going to force an auto relabel of the file system to get all the file context

autorelabel=1 ; force an auto relabel

Using the correct command, create the correct file to trigger an SELinux autorelabel on the next boot.
sudo touch /.autorelabel

There was a problem starting the httpd service. Use the correct commands to investigate the issue and determine if there is an SELinux-related problem. 
If there is an SELinux-related problem, use the correct commands to set the correct SELinux policy settings 
to allow httpd to start correctly. Lastly, start the httpd service.

Run below command to switch to the root user:
sudo -i 
Look into the logs:
journalctl -xe |grep httpd
in the logs I found some Permission denied
 # ausearch -c 'httpd' --raw | audit2allow -M my-httpd
 # semodule -X 300 -i my-httpd.pp
 I run those commands as root
 ausearch -c 'httpd' --raw | audit2allow -M my-httpd      Create a policy module for httpd to run on the port specified in the httpd config file
 semodule -X 300 -i my-httpd.pp                           Load the policy module
 systemctl start httpd.service


We changed the httpd document root to /kodekloud and after that there was a problem 
accessing a web page served by the httpd service, and you suspect it may be due to SELinux file contexts. 
Use the correct commands to investigate why the web page is not working, and restore the correct SELinux file contexts if there is an issue with them.
You can try to access the web page using curl localhost:88/kodekloud.html command and you must get KodeKloud in the output.
Switch to the root user:
sudo -i

Look for SELinux-related error messages:
grep "httpd" /var/log/messages | less

Verify the SELinux file contexts for the files in the document root directory.
ls -laZ /kodekloud/

Set the appropriate context for all files in the /kodekloud/ directory:
semanage fcontext -a -t httpd_sys_content_t "/kodekloud(/.*)?"

Restore the correct contexts:
restorecon -R /kodekloud/



===========================================         Manage Containers     ===============================================================


RHEL8 doesnt have any officil uspport for Docker, we can replace to other tool podman
sudo dnf install docker
it will install podman-docker
we can use docker commands as normal, but it will be podman behind the scene

/etc/containers/registries.conf
comment the lines unqualified-search-registries
create a new line with: unqualified-search-registries=["docker.io"] -> this sets the default software repo of containers to docker.io

to avoid a message pop up after using docker command
sudo touch /etc/containers/nodocker

docker search nginx
docker pull docker.io/library/nginx    OR docker pull nginx             
sudo podman pull docker.io/library/nginx                                

#to check images
docker images

#delete image
docker rmi nginx
docker rmi <image_id>

a non official image need to use a full path

Create a container.
docker run -d <image>
docker run -d nginx
docker run -d docker.io/library/nginx
docker run -d <image_id>

-d: --detach

docker run -d <image> --name <container_name>

docker run -d <image> --name <container_name> -p 8080:80
port mapping fo the container, someone connect at port 8080 it will be redirected to port 80 of the container

to check  use netcat at port 8080
nc localhost 8080
GET /

check containers running
docker ps

check containers exited
docker ps -all

to stop a container
docker stop <container_name-OR-containerID>

to delete a container
docker rm <container_name-OR-containerID>
sudo podman rmi IMAGED_ID -f 
sudo podman rmi IMAGED_ID 

to start a container stopped/exited
docker start <container_name-OR-containerID>

Remove all containers (including running, stopped containers)
sudo podman stop <container_name-OR-containerID>
sudo podman rm <container-id>

podman container based on the nginx image. detach from this container's. map port 1234 on the host to port 80 on the container. name this new container as website.
sudo podman run -d -p 1234:80 --name website nginx


------------- examples
sudo dnf install docker
yum install podman @container-tools

podman login registry.redhat.io
username: bob
password: pass

podman search httpd    # this is to search the image

podman pull docker.io/library/httpd
podman images
podman rmi          # to remove image

podman run -d --name web1 docker.io/library/httpd
podman ps

podman run -d --name web1 -p 8080:80 docker.io/library/httpd        # map the port first is host second container

podman run -d --name web1 -p 8080:80 docker.io/library/httpd -v /path-in-the-host:/usr/local/apache2/htdocs/:Z 
curl localhost:8080/mylocalfilepage.html             #### ls /path-in-the-host/mylocalfilepage.html

# container as a service

for root user 
podman generate systemd web1 > /etc/systemd/system/web1-container.service
systemctl daemon-reload
systemctl start web1-container

for a user, those changes are made in the user login
ssh <username>@localhost
podman pull image docker.io/library/httpd
podman run -d --name New -p 8085:80 docker.io/library/httpd
mkdir -p ~/.config/systemd/user
podman generate systemd New > ~/.config/systemd/user/New-container.service
systemctl --user daemon-reload
systemctl --user start New-container.service
vi  ~/.config/systemd/user/New-container.service
  At the end [Install]
              WantedBy=default.service
systemctl --user daemon-reload
systemctl --user start New-container.service
systemctl --user enable New-container.service


==================================================  Perform container management using commands such as podman and skopeo


man skopeo
man skopeo-copy


Skopeo is a CLI utility that performs various operations on coontainer images/repo

sudo yum install skopeo

like podman, skopeo can be used to inspect repo
unlike podman skopeo can inspect without pulling the image

skopeo inspect docker://registry.fedoraproject.org/fedora:latest

can be used also to inspect containers
skopeo inspect --config docker://registry.fedoraproject.org/fedora:latest | jq

can be used to copy images between different storage mechanisms, like container Registries
skopeo copy docker://quay.io/build/stable docker://registry.enterprise.com/build
first addr is the remote repo
second addr is the registry inside of the enterprise

skopeo copy oci:busy_boxocilayout:latest dir:emptydir

delete image
skopeo delete docker://localhost:5000/imagename

syncing registries
skopeo sync --src docker --dest dir registry.company.com/busybox /media/usb



============================== Configure a container to start automatically as a systemd service and attach persistent storage

to run docker as user (not root) from boot

to switch module screen
first reset
sudo yum module reset container-tools

then install the version you want
sudo yum module install container-tools:3.0

need create a dir under usser home dir
mkdir -p ~/.config/systemd/user


create a persistent storage to use in the container
mkdir -p ~/container_storage

create a container
podman run -d --name container_service -p 1025:8080 -v ~/container_storage:/var/www/html:Z registry.access.redhat.com/rhscl/httpd-24-rhel7

:Z - SELinux

podman ps -a

Create the correct directory for storing systemd service files for the current user bob. Make sure to create any necessary parent directories.
mkdir -p ~/.config/systemd/user
under  ~/.config/systemd/user
generate systemd files 
podman generate systemd --name container_service --files --new 

Use podman to create a rootless systemd service for the kodekloud container. Make sure the service file is stored in the correct directory.
cd ~/.config/systemd/user
sudo podman generate systemd --name kodekloud --files --new

Using the correct commands, make sure the current user is configured to launch rootless systemd services,
and that systemd is aware of this change in the current session.
Next, make sure the kodekloud container service is set to launch as a rootless systemd service at boot.
loginctl enable-linger bob
export XDG_RUNTIME_DIR=/run/user/$(id -u)
systemctl --user daemon-reload
systemctl --user enable container-kodekloud.service --now

to make sure user can launch systemd, need to enable login setting for the user
loginctl enable-linger
systemctl --user daemon-reload

systemd commands is used so that system is aware of new changes in the unit files?
sudo systemctl daemon-reload

systemctl --user enable --now container-container_service.service
sudo systemctl reboot
curl localhost:1025/file.html

podman ps -a



KK - review 
tar/star/bzip
https://kodekloud.com/topic/lab-archive-backup-compress-io-redirection-3/

journalctl, sighup
https://kodekloud.com/topic/lab-manage-processes-and-analyze-log-files-4/





